---
title: "Variations of Poisson GLM Modeling Using Airbnb Data of Melbourne, Australia"
author: |
  | Xixi Chen xc2444; Lixian Chen lc3359; George Liu gjl2116; Yuhao Wang yw3204
  | Deparment of Statistics, Columbia University
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
library(glmnet)
library(MASS)
library(pscl)
```

# Abstract

We analyze a dataset drawn from Airbnb listings in Melbourne, Australia. In order to understand the drivers of conversion and engagement as measured by review count and predict the number of reviews that a listing is able to generate, we attempt to fit a loglinear model (Poisson GLM) as well as its variations in order to deal with overdispersion and zero inflation in the data, given a set of predictors.

In particular, because we are not privy to data about bookings given our data is scraped from the Airbnb site, we leverage factors that are likely to be predictors of historic conversion such as price, instant bookable, and availability. We also consider other variables such as months listed and property type that may have effects on reviews independent of conversion.

# Introduction

Generalized linear models (GLM) play a critical role in categorical data analysis. The Poisson regression model is one special GLM designed to deal with the count data. In this project, we are particularly interested in predicting the number of reviews for each Airbnb host in Melbourne, which can be regarded as a kind of count data and thus may be applied with the Poisson regression model. We will mainly focus on three kinds of models: Poisson regression model, negative binomial regression model and zero inflated Poisson regression model. But we also experimented with Quasi-Poisson model and zero inflated negative binomial model. 

## Generalized linear model
As the name suggests, GLM is a generalization of the traditional linear regression model. We can also say the classic linear regression model is a special case of the GLM when the random component is the normal distribution. More formally, we define the GLM as follows, which consists of 3 parts:

1. The distribution of the response is from the exponential distribution family, which means it has the form:

$$f(y_i| \theta_i) = a(y_i)b(\theta_i)exp(y_i\theta_i)$$

2. The systematic component:

$$\eta_i=\Sigma_{i=1}^{p}\beta_ix_i$$

3. A link function $g(x)$ which links the systematic component and the mean of the response, such as identity link and canonical link:

$$g(\mu_i) = \eta_i$$

## Poisson regression model
As we have mentioned before, Poisson regresssion model is a special GLM. More specifically, it assumes the response has a Poisson distribution and the link function is the canonical link. Mathematically, we write the pdf of the response as:

$$f(y_i| \mu_i) = e^{-\mu_i}\frac{\mu_i^{y_i}}{y_i!}$$

and the canonical link has the form :

$$\eta_i = \log(\mu_i)$$

And this is our Poisson regression model or log-linear model.

## Poisson regression model for rates
It is sometimes more natural for us to fit a Poisson regression model for rates than counts when the response is counted over different periods. We thus begin by specifying a rate model:

$$\log(\mu_i/t_i) = \alpha+\beta*x_i$$
or 

$$\log(\mu_i) = \alpha+\beta*x_i + \log(t_i)$$

in which we call $\log(t_i)$ as offset. 


## Quasi-Poisson regression model
Usually, Poisson regression model is simple and thus it has several drawbacks. One deficiency of Poisson regression model is that it can't deal with a phenomena called overdispersion. An overdispersion occurs when the variance of true response appears to be larger than that of the predicted response. Thus, it is natural for people to come up with a more complicated model to tackle this issue. For example, we can use the quasi-poisson regression model by incorparating a dispersion parameter. 

To introduce the quasi-likelihood regression, we will briefly talk about the likelihood equation of the GLM first. And more generally, we assume that our response is from the exponential dispersion family, which has the form: 

$$f(y_i|\theta_i, \phi)=exp(\frac{y_i\theta_i-b(\theta_i)}{a(\phi)}+c(y_i, \phi))$$. 

Then, the log-likelihood function is:

$$l = \Sigma_{i=1}^n\frac{y_i\theta_i-b(\theta_i)}{a(\phi)}+\Sigma_{i=1}^nc(y_i, \phi)$$

By taking derivative w.r.t $\beta$, the likelihood equation is:

$$\Sigma_{i=1}^n \frac{(y_i-\mu_i)x_{ij}}{var(Y_i)} \frac{\partial\mu_i}{\partial\eta_i}=0, j =1, ..., p$$.

Moreover, the likelihood equation for the Poisson regression is:

$$\Sigma_{i=1}^n \frac{(y_i-\mu_i)x_{ij}}{\mu_i} \frac{\partial\mu_i}{\partial\eta_i}=0, j =1, ..., p$$.

For the quasi-Poisson regression, we change the above equation slightly by introducing the parameter $\phi$:

$$\Sigma_{i=1}^n \frac{(y_i-\mu_i)x_{ij}}{\phi\mu_i} \frac{\partial\mu_i}{\partial\eta_i}=0, j =1, ..., p$$.

This is so-called quasi-Possion regression model.

## Negative binomial regression model
Another option to deal with overdispersion is the negative binomial regression model. That's to say, we will assume the response has a negative binomial distribution. More specifically, if we assume the parameter $\mu$ for the Poisson distribution has a gamma distribution $\Gamma(r, \frac{1-p}{p})$, we can show that the posterior distribution is exactly a negative binomial distribution with parameter $r$ and $p$: $Y \sim NegBinom(r, p)$. 

## Zero inflated Poisson regression model
In real life, not all count data behaves exactly like a Poisson distribution. More often than not, it is common to see 0 overrepresented in the data which is called zero inflation, like what we encountered in our project. To take this into consideration, the zero inflated poisson regression or ZIP model is proposed. The idea is that we slightly change the response distribution by including an additional parameter $\pi_i$ called probability of extra zeros:

$$\mathbb{P}(y_i=0)=\pi_i + (1-\pi_i)e^{-\mu_i}$$
$$\mathbb{P}(y_i=k)=(1-\pi_i)e^{-\mu_i}\frac{\mu_i^k}{k!}$$

## Zero inflated negative binomial model
We also analyze this with an underlying negative binomial distribution as described above. We change the link to negative binomial link. 


# Exploratory data analysis

We quickly explore our response variable by drawing a histogram and a scatter plot against the price and find the empirical distribution of the response variable is not exactly in a form of Poisson distribution. For example, there are more 0 counts in the histogram. Luckliy, the zero inflation Poisson regression model we mentioned above might be used to deal with this issue hopefully. Also, we notice that there is an apparent relationship between the response variable and the price variable by observing the scatter plot. Therefore, we start our basic model by regressing on the price below.
```{r message=FALSE}
# load data
 setwd("~/Documents/5232_GLM/Project/3_sigma-master")
listings_summary <- read.csv("listings_summary_dec18.csv")
listings_cleansed <- read.csv("cleansed_listings_dec18.csv")

# create months variable
listings_cleansed$months <- coalesce(listings_cleansed$number_of_reviews / listings_cleansed$reviews_per_month, as.numeric(strptime(listings_cleansed$last_scraped,format='%m/%d/%Y') - strptime(listings_cleansed$host_since,format='%m/%d/%Y')) / (365.25/12))

listings_joined <- left_join(listings_summary,listings_cleansed[,c('id','months','security_deposit','instant_bookable')])

hist(listings_joined$number_of_reviews, breaks = 100, xlim = c(0, 100), 
     xlab = "", main = "# of reviews")
```

```{r}
plot(listings_joined$price, listings_joined$number_of_reviews, xlim = c(0, 1000), pch=16, 
     cex=0.5, xlab = "price", ylab="# of reviews")
```


# Model building and inference

## Poisson regression model

We first try to fit the simplest model, the Poisson regression model using number of reviews as the response and price as the predictor. 
```{r}
# poisson regression for rates
poi_rates <- glm(number_of_reviews ~ price+offset(log(months)), family = poisson, 
                 data = listings_joined)

summary(poi_rates)

# hist(predict(poi_rates, type = "response"), xlab = "poi predicted", 
#     main = "hist")

# checking overdispersion 
# var(predict(poi_rates, type = "response"))
# var(listings_joined$number_of_reviews)
```
The result above shows that the model coefficient is significant and thus suggests that the price variable should be included. The model can be written as:

$$\log(\mu) = -0.0556 - 8.96*10^{-4}*x$$.

It suggests there is a negative relationship between number of reviews and the price, which is legitimate since the more expensive, the fewer the guests and thus the fewer the number of reviews. We then plot the residuals against the fitted value and conduct the goodness of fit test.

We then compare the model with the saturated model using analysis with deviance. It also suggests that the p-value is small enough for us to accept the alternative that the number of reviews drops as the price increases.
```{r}
# saturated model
poi_sat <- glm(number_of_reviews~1+offset(log(months)), family=poisson, data=listings_joined)
# hist(predict(poi_sat, type = "response"), xlab = "predicted", main = "saturated model hist")

# analysis of deviance testing model significance
anova(poi_sat, poi_rates, test = "Chisq")
```

```{r}
# # residual plots
# plot(poi_rates$fitted.values, poi_rates$residuals, cex=0.5, 
#      pch=16, ylim = c(-1, 15))

# goodness of fit test
# 1-pchisq(poi_rates$deviance, poi_rates$df.residual)
```

## More covariates
Next, we try to add two more covariate into the above and perform the same pocedure, the availability_365 and instant_bookable. We also try to compare models with the saturated model using deviance. The results shows the two added covariates is also significant. The deviance plot comparing the three model is more straight forward.
```{r}
# poisson regression 1
poi_rates_1 <- glm(number_of_reviews ~ price+availability_365+instant_bookable+offset(log(months)), 
                   family = poisson, data = listings_joined)
# summary(poi_rates_1)
anova(poi_sat, poi_rates_1, test = "Chisq")
```

```{r}
# model deviance comparison
plot(c(poi_sat$deviance, poi_rates$deviance, poi_rates_1$deviance), 
     ylab = "deviance", xlab = "models", main = "Poisson model deviance plot")
lines(c(poi_sat$deviance, poi_rates$deviance, poi_rates_1$deviance))
text(x=c(1.2, 2, 2.6), y=c(930000, 920000, 860000), labels = 
         c("saturated", "one covariate", "three covariates"))

# model aic comparison
# plot(c(poi_sat$aic, poi_rates$aic, poi_rates_1$aic), 
#      ylab = "AIC", xlab = "models", main = "AIC plot")
# lines(c(poi_sat$aic, poi_rates$aic, poi_rates_1$aic))

# hist(predict(poi_rates_1, type = "response"), xlab = "poi_1 predicted", 
#     main = "hist")

# goodness of fit test for 1
# 1-pchisq(poi_rates_1$deviance, poi_rates_1$df.residual)
# var(listings_summary$number_of_reviews)
```

Even though the models above are significant to some extent. We know that Poisson regression model is not perfect. Especially, it has a common problem called overdispersion. We then try to check the issue by comparing the response variance and the predicted value variance.
```{r}
# checking overdispersion 
print("true variance:")
print(var(listings_joined$number_of_reviews))
print("predicted variance 1:")
print(var(predict(poi_rates, type = "response")))
print("predicted variance 2:")
print(var(predict(poi_rates_1, type = "response")))
```
It is obvious that, the original data has a severe problem of overdispersion which suggests us other methods to predict the response. We then turn to fit the negative binomial model.


## Fitting negative binomial regression
We have already selected three significant variables above and we will use them as the assumed predictors for our negative binomial model here. The model output is shown below. We can see that the results are significant. We then calculte the predicted respose variance of the model and find it increases compared to those Poisson models, which is 549.05 here.
```{r}
neg_bin_rates <- glm.nb(number_of_reviews~price+availability_365+instant_bookable+
                        +offset(log(months)), data=listings_joined, init.theta = 0.1)

summary(neg_bin_rates)

# plot(neg_bin_rates$fitted.values, neg_bin_rates$residuals, ylim = c(-1, 10), pch=16, cex=0.4,
#     xlab = "fitted value", ylab = "residual", main = "negative binomial")

# hist(predict(neg_bin_rates, type="response"), xlab = "predicted", 
#      main = "negative binomial", breaks = 20)

print("true variance:")
print(var(listings_joined$number_of_reviews))
print("predicted variance:")
print(var(predict(neg_bin_rates, type = "response")))
# 1-pchisq(neg_bin_rates$deviance, neg_bin_rates$df.residual)
```


## Fitting ZIP model
As we mentioned before, when observing the response histogram plot, we notice that there is an interesting phenomenon: the number of 0 counts is far more than others. We now try to fit the so called zero inflation Poisson model. Similarly, we find those predictors are also significant in the zero inflation Poisson model according to the output.
```{r}
zip_rates <- zeroinfl(number_of_reviews~price+availability_365+instant_bookable+offset(log(months)), 
                        data=listings_joined)
summary(zip_rates)

# plot(zip_rates$fitted.values, zip_rates$residuals, pch=16, cex=0.5, 
#      ylab="residuals", xlab="fitted value", main = "zero inflated model")

# hist(predict(zip_rates, type="response")*
#        sapply(1-predict(zip_rates, type="zero"), rbinom, n=1, size=1), 
#      breaks = 20, xlim = c(0,100))

# hist(predict(zip_rates, type="response"), main = "zero inflated model", 
#      xlab = "predicted", breaks = 10)
```

Also, in the zero inflation model function, by changing the link to negative binomial link, it will give us the zero inflation negative binomial model. The output is shown below.
```{r}
# negative binomial link
zip_rates_1<- zeroinfl(number_of_reviews~price+availability_365+instant_bookable+
                          offset(log(months)), dist = "negbin",data=listings_joined)

# plot(zip_rates_1$fitted.values, zip_rates$residuals, pch=16, cex=0.5, 
#      ylab="residuals", xlab="fitted value", main = "zero inflated model")

# hist(predict(zip_rates_1, type="response")*
#        sapply(1-predict(zip_rates, type="zero"), rbinom, n=1, size=1), 
#      breaks = 40, xlim = c(0,100))

summary(zip_rates_1)
# var(predict(zip_rates, type = "response"))
# var(listings_joined$number_of_reviews)
```


# Model comparison
We compare models mainly from three perspectives: predicted value, residual and Vuong test. 

## Predicted value comparison
According to the following predicted value plots of the models, we find both zero inflation models and zero inflation negative binomial models deal with the zero inflation issue relatively better. 

```{r}
par(mfrow=c(2, 2))

# zero inflation-negative binomial model
hist(listings_joined$number_of_reviews, col=rgb(0,0,1,1/4), xlim = c(0, 100), 
     breaks = 100, main="zero inflation-negative binomial model", xlab="")
hist(predict(zip_rates_1, type="response")*
         sapply(1-predict(zip_rates_1, type="zero"), rbinom, n=1, size=1), 
     breaks = 40, xlim = c(0,100), add=T, col=rgb(1,0,0,1/4))
legend(50, 10000, legend=c("original data", "predicted value"),
       col=c(rgb(0,0,1,1/4), rgb(1,0,0,1/4)), pch = c(16, 16), cex=0.8)

# zero inflation-Poisson model
hist(listings_joined$number_of_reviews, col=rgb(0,0,1,1/4), xlim = c(0, 100), 
     breaks = 100, main="zero inflation-Poisson model", xlab="")
hist(predict(zip_rates, type="response")*
         sapply(1-predict(zip_rates, type="zero"), rbinom, n=1, size=1), 
     breaks = 40, xlim = c(0,100), add=T, col=rgb(1,0,0,1/4))
legend(50, 10000, legend=c("original data", "predicted value"),
       col=c(rgb(0,0,1,1/4), rgb(1,0,0,1/4)), pch = c(16, 16), cex=0.8)

# negative binomial
hist(listings_joined$number_of_reviews, col=rgb(0,0,1,1/4), xlim = c(0, 100), 
     breaks = 100, xlab = "", main = "negative binomial model")
hist(neg_bin_rates$fitted.values, add=T, col=rgb(1,0,0,1/4), breaks = 40)
legend(50, 10000, legend=c("original data", "predicted value"),
       col=c(rgb(0,0,1,1/4), rgb(1,0,0,1/4)), pch = c(16, 16), cex=0.8)

# poisson model
hist(listings_joined$number_of_reviews, col=rgb(0,0,1,1/4), xlim = c(0, 100), 
     breaks = 100, main = "Poisson model", xlab = "")
hist(poi_rates_1$fitted.values, add=T, col=rgb(1,0,0,1/4), breaks = 40)
legend(50, 10000, legend=c("original data", "predicted value"),
       col=c(rgb(0,0,1,1/4), rgb(1,0,0,1/4)), pch = c(16, 16), cex=0.8)
```

## Residual comparison
We then plot the residual plots and find both Poisson regression model and negative binomial model have a problem of heteroscidaticity. But for zero inflated Poisson and zero inflated negarive binomail model, this issue seems less severe.

```{r}
par(mfrow=c(2, 2))

plot(poi_rates_1$fitted.values, poi_rates_1$residuals, ylim = c(-1, 15), pch=16, cex=0.4,
     xlab = "fitted value", ylab = "residual", main = "poisson")

plot(neg_bin_rates$fitted.values, neg_bin_rates$residuals, ylim = c(-1, 15), pch=16, cex=0.4,
     xlab = "fitted value", ylab = "residual", main = "negative binomial")

plot(zip_rates$fitted.values, zip_rates$residuals, pch=16, cex=0.4,
     xlab = "fitted value", ylab = "residual", main = "zip")

plot(zip_rates_1$fitted.values, zip_rates_1$residuals, pch=16, cex=0.4,
     xlab = "fitted value", ylab = "residual", main = "zinb")
```


## Vuong test
Vuong test is a likelihood based test for model comparison using the KL divergence criterion. It is suitable for not just nested models, but also non-nested models. According to the output below, we conclude that: zero inflation negative binomial model > negative binomial model > zero inflation Poisson model > Poisson model. It is also explainable. Because for the zero inflated negative binomial model, it takes both zero inflation and overdispersion into account and thus it is undoubtedly the best. While for zero inflated Poisson and negative binomial model, both models only deal with one part of the issues and thus it is not easy to predict which one is better beforehand. All Vuong test results are summarized in the table below.

```{r}
# vuong(poi_rates_1, neg_bin_rates)
# vuong(zip_rates, neg_bin_rates)
# vuong(zip_rates_1, neg_bin_rates)
# vuong(zip_rates, zip_rates_1)
# vuong(zip_rates_1, poi_rates_1)
```


|Models Compared|Vuong z-statistic|
| --- | --- |
|Poisson and Negative Binomial|79.34|
|Poisson and Zero-inflated Poisson|79.74|
|Zero-inflated Poisson and Negative Binomial|62.27|
|Zero-inflated Negative Binomial and Negative Binomial|36.45|
|Zero-inflated Poisson and Zero-inflated Negative Binomial|63.45|


# Conclusion

We tested the Poisson, negative binomial Poisson, quasi-Poisson, zero-inflated Poisson, zero-inflated negative binomial models. We also compared Poisson models with 0 predictors, 1 predictor, and 3 predictors. For the quasi Poisson, due to irregular outputs with an extremely high predicted $\phi$ value, we decided not to utilize this model.

We were able to produce a model which we felt had reasonable predictive power, in which we see a negative relationship between price and reviews, but a positive one in availability and Instant Book status. None of the coefficients indicates a surprising conclusion, so this model is one that we would feel comfortable with.

However as we can see from the histogram there are still areas which can be refined. For instance, we can see that our model provides higher weights in the mid-range of review count. We also observe that there are certain residuals that are quite large.

The natural next steps are to understand the points with large residuals to see whether they have excessive leverage, and to refine our understanding of the number of low-review count and whether we could introduce additional variables to improve the fit.


# Reference

* Tyler Xie. (2019). Melbourne AirBnB Open Data. (Version 10) [Data files]. Retrieved from https://www.kaggle.com/tylerx/melbourne-airbnb-open-data/
* Vuong, Quang H. (1989). "Likelihood Ratio Tests for Model Selection and non-nested Hypotheses". Econometrica. 57 (2): 307â€“333. JSTOR 1912557.
* Agresti, Alan. (2012) Categorical Data Analysis (3rd ed.). Hoboken, NJ: John Wiley and Sons


<!-- --- -->
<!-- references: -->
<!-- - title: Melbourne AirBnB Open Data -->
<!--   author: -->
<!--   - family: Xie -->
<!--     given: Tyler -->
<!--   URL: 'https://www.kaggle.com/tylerx/melbourne-airbnb-open-data/' -->
<!--   publisher: Kaggle -->
<!--   type: Data Files -->
<!--   issued: -->
<!--     year: 2019 -->

<!-- - title: Categorical Data Analysis -->
<!--   author: -->
<!--   - family: Alan -->
<!--     given: Agresti -->
<!--   publisher: Hoboken, NJ: John Wiley and Sons -->
<!--   page: 261-263 -->
<!--   issued: -->
<!--     year: 2012 -->

<!-- - title: Likelihood Ratio Tests for Model Selection and non-nested Hypotheses -->
<!--   author: -->
<!--   - family: Quang -->
<!--     given: Vuong -->
<!--   issue: 4 -->
<!--   publisher: Econometrica -->
<!--   type: article-journal -->
<!--   issued: -->
<!--     year: 1989 -->
<!-- --- -->







